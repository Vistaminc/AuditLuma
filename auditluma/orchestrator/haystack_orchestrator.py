"""
Haystackä¸»ç¼–æ’æ¡†æ¶ - å±‚çº§RAGæ¶æ„ç¬¬ä¸€å±‚
è´Ÿè´£ä»»åŠ¡åˆ†å‘ã€æµç¨‹ç¼–æ’å’Œç»“æœæ±‡æ€»
"""

import asyncio
import uuid
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import time
from pathlib import Path

from loguru import logger

from auditluma.config import Config
from auditluma.models.code import SourceFile, CodeUnit, VulnerabilityResult
from auditluma.rag.txtai_retriever import TxtaiRetriever
from auditluma.rag.r2r_enhancer import R2REnhancer
from auditluma.rag.self_rag_validator import SelfRAGValidator
from auditluma.orchestrator.task_decomposer import TaskDecomposer, TaskCollection
from auditluma.orchestrator.parallel_executor import ParallelProcessingManager, TaskScheduler
from auditluma.orchestrator.result_integrator import ResultIntegrator, ConflictResolutionStrategy


# Import data structures from task_decomposer
from auditluma.orchestrator.task_decomposer import TaskType, AuditTask


@dataclass
class TaskResult:
    """ä»»åŠ¡æ‰§è¡Œç»“æœ"""
    task_id: str
    task_type: TaskType
    vulnerabilities: List[VulnerabilityResult]
    execution_time: float
    confidence: float
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AuditResult:
    """ç»¼åˆå®¡è®¡ç»“æœ"""
    vulnerabilities: List[VulnerabilityResult]
    task_results: List[TaskResult]
    execution_summary: Dict[str, Any]
    confidence_score: float
    processing_time: float


class HaystackOrchestrator:
    """Haystackä¸»ç¼–æ’å™¨ - å±‚çº§RAGæ¶æ„çš„æ ¸å¿ƒç¼–æ’ç»„ä»¶"""
    
    def __init__(self, workers: int = 10):
        """åˆå§‹åŒ–ç¼–æ’å™¨"""
        self.workers = workers
        self.task_queue = asyncio.Queue()
        self.result_queue = asyncio.Queue()
        
        # åˆå§‹åŒ–å„å±‚ç»„ä»¶
        self.txtai_retriever = TxtaiRetriever()
        self.r2r_enhancer = R2REnhancer()
        self.self_rag_validator = SelfRAGValidator()
        
        # åˆå§‹åŒ–ä»»åŠ¡åˆ†è§£å™¨ã€å¹¶è¡Œæ‰§è¡Œå™¨å’Œç»“æœæ•´åˆå™¨
        self.task_decomposer = TaskDecomposer()
        self.parallel_executor = ParallelProcessingManager(max_workers=workers)
        self.task_scheduler = TaskScheduler()
        self.result_integrator = ResultIntegrator()
        
        # ä»»åŠ¡æ‰§è¡Œå™¨æ˜ å°„
        from auditluma.orchestrator.task_decomposer import TaskType
        self.task_executors = {
            TaskType.SYNTAX_CHECK: self._execute_syntax_check,
            TaskType.LOGIC_ANALYSIS: self._execute_logic_analysis,
            TaskType.SECURITY_SCAN: self._execute_security_scan,
            TaskType.DEPENDENCY_ANALYSIS: self._execute_dependency_analysis
        }
        
        # æ€§èƒ½ç›‘æ§
        self.performance_metrics = {
            "tasks_completed": 0,
            "total_execution_time": 0.0,
            "layer_performance": {
                "txtai": {"calls": 0, "total_time": 0.0},
                "r2r": {"calls": 0, "total_time": 0.0},
                "self_rag": {"calls": 0, "total_time": 0.0}
            }
        }
        
        # å…¼å®¹æ€§æ”¯æŒ - æ¨¡æ‹ŸAgentOrchestratorçš„å±æ€§
        self.agents = {}
        self.code_units = []
        
        logger.info(f"Haystackç¼–æ’å™¨åˆå§‹åŒ–å®Œæˆï¼Œå·¥ä½œçº¿ç¨‹æ•°: {workers}")
    
    async def orchestrate_audit(self, source_files: List[SourceFile]) -> AuditResult:
        """ä¸»ç¼–æ’æµç¨‹ - æ‰§è¡Œå®Œæ•´çš„å±‚çº§RAGå®¡è®¡"""
        start_time = time.time()
        logger.info(f"ğŸš€ å¼€å§‹Haystackå±‚çº§RAGå®¡è®¡ï¼Œæ–‡ä»¶æ•°: {len(source_files)}")
        
        try:
            # 1. ä»»åŠ¡åˆ†è§£
            task_collection = await self._decompose_audit_tasks(source_files)
            logger.info(f"ğŸ“‹ ä»»åŠ¡åˆ†è§£å®Œæˆï¼Œç”Ÿæˆ {len(task_collection)} ä¸ªå®¡è®¡ä»»åŠ¡")
            
            # 2. å¹¶è¡Œæ‰§è¡Œå„ç±»ä»»åŠ¡
            task_results = await self._execute_tasks_parallel(task_collection.tasks)
            logger.info(f"âš¡ å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œè·å¾— {len(task_results)} ä¸ªç»“æœ")
            
            # 3. æ”¶é›†æ‰€æœ‰æ¼æ´
            all_vulnerabilities = []
            for result in task_results:
                all_vulnerabilities.extend(result.vulnerabilities)
            
            # 4. txtaiå±‚ï¼šçŸ¥è¯†æ£€ç´¢å¢å¼º
            enhanced_vulnerabilities = await self._apply_txtai_enhancement(all_vulnerabilities)
            logger.info(f"ğŸ” txtaiçŸ¥è¯†æ£€ç´¢å®Œæˆï¼Œå¢å¼ºäº† {len(enhanced_vulnerabilities)} ä¸ªæ¼æ´")
            
            # 5. R2Rå±‚ï¼šä¸Šä¸‹æ–‡å¢å¼º
            context_enhanced_vulnerabilities = await self._apply_r2r_enhancement(
                enhanced_vulnerabilities, source_files
            )
            logger.info(f"ğŸ”— R2Rä¸Šä¸‹æ–‡å¢å¼ºå®Œæˆï¼Œå¤„ç†äº† {len(context_enhanced_vulnerabilities)} ä¸ªæ¼æ´")
            
            # 6. Self-RAGå±‚ï¼šéªŒè¯ä¸è¿‡æ»¤
            validated_vulnerabilities = await self._apply_self_rag_validation(
                context_enhanced_vulnerabilities
            )
            logger.info(f"âœ… Self-RAGéªŒè¯å®Œæˆï¼ŒéªŒè¯äº† {len(validated_vulnerabilities)} ä¸ªæ¼æ´")
            
            # 7. ç»“æœæ•´åˆ
            audit_result = await self._integrate_results(
                validated_vulnerabilities, task_results, start_time
            )
            
            # 8. æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            self._update_performance_metrics(audit_result.processing_time)
            
            logger.info(f"ğŸ‰ Haystackå±‚çº§RAGå®¡è®¡å®Œæˆï¼Œè€—æ—¶: {audit_result.processing_time:.2f}ç§’")
            logger.info(f"ğŸ“Š å‘ç°æ¼æ´: {len(audit_result.vulnerabilities)}ï¼Œç½®ä¿¡åº¦: {audit_result.confidence_score:.2f}")
            
            # 9. è¾“å‡ºæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
            try:
                from auditluma.monitoring.model_usage_logger import model_usage_logger
                logger.info("ğŸ“Š ç”Ÿæˆæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡æ‘˜è¦...")
                model_usage_logger.print_session_summary()
            except Exception as e:
                logger.warning(f"ç”Ÿæˆæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            
            return audit_result
            
        except Exception as e:
            logger.error(f"âŒ Haystackç¼–æ’è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    async def _decompose_audit_tasks(self, source_files: List[SourceFile]) -> TaskCollection:
        """ä»»åŠ¡åˆ†è§£ - ä½¿ç”¨ä¸“é—¨çš„ä»»åŠ¡åˆ†è§£å™¨"""
        return await self.task_decomposer.decompose_audit_tasks(source_files)
    
    async def _execute_tasks_parallel(self, tasks: List[AuditTask]) -> List[TaskResult]:
        """å¹¶è¡Œæ‰§è¡Œä»»åŠ¡ - ä½¿ç”¨ä¸“é—¨çš„å¹¶è¡Œæ‰§è¡Œå¼•æ“"""
        if not tasks:
            return []
        
        # è°ƒåº¦ä»»åŠ¡æ‰§è¡Œé¡ºåº
        scheduled_tasks = self.task_scheduler.schedule_tasks(
            TaskCollection(tasks=tasks), strategy="hybrid"
        )
        
        # åˆ›å»ºä»»åŠ¡æ‰§è¡Œå™¨
        async def task_executor_wrapper(task: AuditTask):
            """ä»»åŠ¡æ‰§è¡Œå™¨åŒ…è£…"""
            try:
                executor = self.task_executors[task.task_type]
                vulnerabilities = await executor(task)
                
                confidence = self._calculate_task_confidence(task, vulnerabilities)
                
                return TaskResult(
                    task_id=task.id,
                    task_type=task.task_type,
                    vulnerabilities=vulnerabilities,
                    execution_time=0.0,  # å°†ç”±å¹¶è¡Œæ‰§è¡Œå™¨è®¡ç®—
                    confidence=confidence,
                    metadata=task.metadata
                )
            except Exception as e:
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.id}, {e}")
                return TaskResult(
                    task_id=task.id,
                    task_type=task.task_type,
                    vulnerabilities=[],
                    execution_time=0.0,
                    confidence=0.0,
                    metadata={"error": str(e)}
                )
        
        # ä½¿ç”¨å¹¶è¡Œæ‰§è¡Œå¼•æ“æ‰§è¡Œä»»åŠ¡
        execution_result = await self.parallel_executor.execute_tasks(
            scheduled_tasks, task_executor_wrapper
        )
        
        # è½¬æ¢æ‰§è¡Œç»“æœä¸ºTaskResultåˆ—è¡¨
        task_results = []
        for task_execution in execution_result.task_executions:
            if task_execution.result and isinstance(task_execution.result, TaskResult):
                # æ›´æ–°æ‰§è¡Œæ—¶é—´
                task_execution.result.execution_time = task_execution.execution_time
                task_results.append(task_execution.result)
            else:
                # åˆ›å»ºå¤±è´¥çš„TaskResult
                task_result = TaskResult(
                    task_id=task_execution.task.id,
                    task_type=task_execution.task.task_type,
                    vulnerabilities=[],
                    execution_time=task_execution.execution_time,
                    confidence=0.0,
                    metadata={
                        "status": task_execution.status.value,
                        "error": str(task_execution.error) if task_execution.error else None,
                        "retry_count": task_execution.retry_count,
                        "worker_id": task_execution.worker_id
                    }
                )
                task_results.append(task_result)
        
        # è®°å½•å¹¶è¡Œæ‰§è¡Œç»Ÿè®¡
        logger.info(f"å¹¶è¡Œæ‰§è¡Œç»Ÿè®¡: æˆåŠŸ {execution_result.successful_tasks}, "
                   f"å¤±è´¥ {execution_result.failed_tasks}, "
                   f"è¶…æ—¶ {execution_result.timeout_tasks}")
        
        return task_results
    
    async def _apply_txtai_enhancement(self, vulnerabilities: List[VulnerabilityResult]) -> List[VulnerabilityResult]:
        """åº”ç”¨txtaiå±‚çŸ¥è¯†æ£€ç´¢å¢å¼º"""
        start_time = time.time()
        
        enhanced_vulnerabilities = []
        for vuln in vulnerabilities:
            try:
                # ä½¿ç”¨txtaiæ£€ç´¢ç›¸å…³çŸ¥è¯†
                knowledge_info = await self.txtai_retriever.retrieve_vulnerability_info(
                    vuln.vulnerability_type, vuln.snippet
                )
                
                # å¢å¼ºæ¼æ´ä¿¡æ¯
                enhanced_vuln = await self.txtai_retriever.enhance_vulnerability(
                    vuln, knowledge_info
                )
                enhanced_vulnerabilities.append(enhanced_vuln)
                
            except Exception as e:
                logger.warning(f"txtaiå¢å¼ºå¤±è´¥: {vuln.id}, {e}")
                enhanced_vulnerabilities.append(vuln)  # ä¿ç•™åŸå§‹æ¼æ´
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        execution_time = time.time() - start_time
        self.performance_metrics["layer_performance"]["txtai"]["calls"] += 1
        self.performance_metrics["layer_performance"]["txtai"]["total_time"] += execution_time
        
        return enhanced_vulnerabilities
    
    async def _apply_r2r_enhancement(self, vulnerabilities: List[VulnerabilityResult], 
                                   source_files: List[SourceFile]) -> List[VulnerabilityResult]:
        """åº”ç”¨R2Rå±‚ä¸Šä¸‹æ–‡å¢å¼º"""
        start_time = time.time()
        
        # æ„å»ºå…¨å±€ä¸Šä¸‹æ–‡
        global_context = await self.r2r_enhancer.build_global_context(source_files)
        
        enhanced_vulnerabilities = []
        for vuln in vulnerabilities:
            try:
                # å¢å¼ºä»£ç ä¸Šä¸‹æ–‡
                enhanced_context = await self.r2r_enhancer.enhance_context(
                    vuln, global_context
                )
                
                # åº”ç”¨ä¸Šä¸‹æ–‡å¢å¼º
                enhanced_vuln = await self.r2r_enhancer.apply_context_enhancement(
                    vuln, enhanced_context
                )
                enhanced_vulnerabilities.append(enhanced_vuln)
                
            except Exception as e:
                logger.warning(f"R2Rå¢å¼ºå¤±è´¥: {vuln.id}, {e}")
                enhanced_vulnerabilities.append(vuln)  # ä¿ç•™åŸå§‹æ¼æ´
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        execution_time = time.time() - start_time
        self.performance_metrics["layer_performance"]["r2r"]["calls"] += 1
        self.performance_metrics["layer_performance"]["r2r"]["total_time"] += execution_time
        
        return enhanced_vulnerabilities
    
    async def _apply_self_rag_validation(self, vulnerabilities: List[VulnerabilityResult]) -> List[VulnerabilityResult]:
        """åº”ç”¨Self-RAGå±‚éªŒè¯ä¸è¿‡æ»¤"""
        start_time = time.time()
        
        validated_vulnerabilities = []
        for vuln in vulnerabilities:
            try:
                # æ‰§è¡ŒéªŒè¯
                validation_result = await self.self_rag_validator.validate_vulnerability(vuln)
                
                if validation_result.is_valid:
                    # æ›´æ–°ç½®ä¿¡åº¦å’ŒéªŒè¯ä¿¡æ¯
                    vuln.confidence = validation_result.confidence_score
                    vuln.validation_metadata = validation_result.metadata
                    validated_vulnerabilities.append(vuln)
                else:
                    logger.debug(f"æ¼æ´è¢«Self-RAGè¿‡æ»¤: {vuln.id}, åŸå› : {validation_result.rejection_reason}")
                
            except Exception as e:
                logger.warning(f"Self-RAGéªŒè¯å¤±è´¥: {vuln.id}, {e}")
                validated_vulnerabilities.append(vuln)  # ä¿ç•™åŸå§‹æ¼æ´
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        execution_time = time.time() - start_time
        self.performance_metrics["layer_performance"]["self_rag"]["calls"] += 1
        self.performance_metrics["layer_performance"]["self_rag"]["total_time"] += execution_time
        
        return validated_vulnerabilities
    
    async def _integrate_results(self, vulnerabilities: List[VulnerabilityResult], 
                               task_results: List[TaskResult], start_time: float) -> AuditResult:
        """ç»“æœæ•´åˆ - ä½¿ç”¨ä¸“é—¨çš„ç»“æœæ•´åˆå™¨"""
        processing_time = time.time() - start_time
        
        # ä½¿ç”¨ç»“æœæ•´åˆå™¨è¿›è¡Œæ™ºèƒ½æ•´åˆ
        integration_result = await self.result_integrator.integrate_results(
            task_results, ConflictResolutionStrategy.CONSENSUS
        )
        
        # ä½¿ç”¨æ•´åˆåçš„æ¼æ´
        final_vulnerabilities = integration_result.integrated_vulnerabilities
        
        # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
        if final_vulnerabilities:
            confidence_score = sum(v.confidence for v in final_vulnerabilities) / len(final_vulnerabilities)
        else:
            confidence_score = 1.0
        
        # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
        execution_summary = {
            "total_tasks": len(task_results),
            "successful_tasks": len([r for r in task_results if not r.metadata.get("error")]),
            "total_vulnerabilities": len(final_vulnerabilities),
            "original_vulnerabilities": len(vulnerabilities),
            "duplicate_count": integration_result.duplicate_count,
            "conflict_count": integration_result.conflict_count,
            "processing_time": processing_time,
            "integration_time": integration_result.processing_time,
            "layer_performance": self.performance_metrics["layer_performance"],
            "task_breakdown": {
                task_type.value: len([r for r in task_results if r.task_type == task_type])
                for task_type in TaskType
            },
            "quality_metrics": integration_result.quality_metrics,
            "integration_metadata": integration_result.integration_metadata
        }
        
        return AuditResult(
            vulnerabilities=final_vulnerabilities,
            task_results=task_results,
            execution_summary=execution_summary,
            confidence_score=confidence_score,
            processing_time=processing_time
        )
    
    # ä»»åŠ¡æ‰§è¡Œå™¨å®ç°
    async def _execute_syntax_check(self, task: AuditTask) -> List[VulnerabilityResult]:
        """æ‰§è¡Œè¯­æ³•æ£€æŸ¥ä»»åŠ¡"""
        # è¿™é‡Œå¯ä»¥é›†æˆç°æœ‰çš„è¯­æ³•æ£€æŸ¥é€»è¾‘
        # æˆ–è€…è°ƒç”¨ä¸“é—¨çš„è¯­æ³•æ£€æŸ¥ä»£ç†
        vulnerabilities = []
        
        for code_unit in task.code_units:
            # ç®€åŒ–çš„è¯­æ³•æ£€æŸ¥é€»è¾‘
            if await self._has_syntax_issues(code_unit):
                vuln = VulnerabilityResult(
                    id=f"syntax_{uuid.uuid4().hex[:8]}",
                    vulnerability_type="Syntax Error",
                    severity="low",
                    description="ä»£ç è¯­æ³•é—®é¢˜",
                    file_path=str(code_unit.source_file.path),
                    start_line=code_unit.start_line,
                    end_line=code_unit.end_line,
                    snippet=code_unit.content[:200],
                    confidence=0.9
                )
                vulnerabilities.append(vuln)
        
        return vulnerabilities
    
    async def _execute_logic_analysis(self, task: AuditTask) -> List[VulnerabilityResult]:
        """æ‰§è¡Œé€»è¾‘åˆ†æä»»åŠ¡"""
        # é›†æˆç°æœ‰çš„é€»è¾‘åˆ†æåŠŸèƒ½
        from auditluma.agents.security_analyst import SecurityAnalystAgent
        
        agent = SecurityAnalystAgent(f"logic_analyst_{uuid.uuid4().hex[:6]}")
        await agent.start()
        
        vulnerabilities = []
        for code_unit in task.code_units:
            try:
                task_data = {
                    "code_unit": code_unit,
                    "analysis_type": "logic_analysis"
                }
                unit_vulns = await agent.execute_task("analyze_code_logic", task_data)
                vulnerabilities.extend(unit_vulns)
            except Exception as e:
                logger.warning(f"é€»è¾‘åˆ†æå¤±è´¥: {code_unit.id}, {e}")
        
        return vulnerabilities
    
    async def _execute_security_scan(self, task: AuditTask) -> List[VulnerabilityResult]:
        """æ‰§è¡Œå®‰å…¨æ‰«æä»»åŠ¡"""
        # é›†æˆç°æœ‰çš„å®‰å…¨æ‰«æåŠŸèƒ½
        from auditluma.agents.security_analyst import SecurityAnalystAgent
        
        agent = SecurityAnalystAgent(f"security_analyst_{uuid.uuid4().hex[:6]}")
        await agent.start()
        
        vulnerabilities = []
        for code_unit in task.code_units:
            try:
                task_data = {
                    "code_unit": code_unit,
                    "analysis_type": "security_scan"
                }
                unit_vulns = await agent.execute_task("analyze_code_security", task_data)
                vulnerabilities.extend(unit_vulns)
            except Exception as e:
                logger.warning(f"å®‰å…¨æ‰«æå¤±è´¥: {code_unit.id}, {e}")
        
        return vulnerabilities
    
    async def _execute_dependency_analysis(self, task: AuditTask) -> List[VulnerabilityResult]:
        """æ‰§è¡Œä¾èµ–åˆ†æä»»åŠ¡"""
        # é›†æˆç°æœ‰çš„ä¾èµ–åˆ†æåŠŸèƒ½
        from auditluma.agents.code_analyzer import CodeAnalyzerAgent
        
        agent = CodeAnalyzerAgent(f"dependency_analyzer_{uuid.uuid4().hex[:6]}")
        await agent.start()
        
        vulnerabilities = []
        try:
            task_data = {
                "code_units": task.code_units,
                "analysis_type": "dependency_analysis"
            }
            vulnerabilities = await agent.execute_task("analyze_dependencies", task_data)
        except Exception as e:
            logger.warning(f"ä¾èµ–åˆ†æå¤±è´¥: {task.id}, {e}")
        
        return vulnerabilities
    
    # è¾…åŠ©æ–¹æ³•
    async def _extract_code_units(self, source_files: List[SourceFile]) -> List[CodeUnit]:
        """æå–ä»£ç å•å…ƒ"""
        # é›†æˆç°æœ‰çš„ä»£ç å•å…ƒæå–é€»è¾‘
        from auditluma.parsers.code_parser import CodeParser
        
        code_units = []
        parser = CodeParser()
        
        for source_file in source_files:
            try:
                file_units = await parser.parse_file_async(source_file)
                code_units.extend(file_units)
            except Exception as e:
                logger.warning(f"è§£ææ–‡ä»¶å¤±è´¥: {source_file.path}, {e}")
        
        return code_units
    

    
    def _calculate_task_confidence(self, task: AuditTask, vulnerabilities: List[VulnerabilityResult]) -> float:
        """è®¡ç®—ä»»åŠ¡ç½®ä¿¡åº¦"""
        if not vulnerabilities:
            return 1.0
        
        # åŸºäºæ¼æ´æ•°é‡å’Œç±»å‹è®¡ç®—ç½®ä¿¡åº¦
        base_confidence = 0.8
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´
        type_multipliers = {
            TaskType.SYNTAX_CHECK: 0.95,
            TaskType.LOGIC_ANALYSIS: 0.85,
            TaskType.SECURITY_SCAN: 0.80,
            TaskType.DEPENDENCY_ANALYSIS: 0.90
        }
        
        multiplier = type_multipliers.get(task.task_type, 0.8)
        return min(1.0, base_confidence * multiplier)
    
    async def _has_syntax_issues(self, code_unit: CodeUnit) -> bool:
        """æ£€æŸ¥ä»£ç å•å…ƒæ˜¯å¦æœ‰è¯­æ³•é—®é¢˜"""
        # ç®€åŒ–çš„è¯­æ³•æ£€æŸ¥é€»è¾‘
        content = code_unit.content
        
        # æ£€æŸ¥å¸¸è§è¯­æ³•é—®é¢˜
        syntax_issues = [
            'SyntaxError',
            'IndentationError',
            'TabError',
            'unexpected EOF',
            'invalid syntax'
        ]
        
        return any(issue in content for issue in syntax_issues)
    
    def _update_performance_metrics(self, processing_time: float):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        self.performance_metrics["tasks_completed"] += 1
        self.performance_metrics["total_execution_time"] += processing_time
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        total_tasks = self.performance_metrics["tasks_completed"]
        if total_tasks == 0:
            return {"message": "å°šæœªæ‰§è¡Œä»»ä½•ä»»åŠ¡"}
        
        avg_execution_time = self.performance_metrics["total_execution_time"] / total_tasks
        
        layer_summary = {}
        for layer, metrics in self.performance_metrics["layer_performance"].items():
            if metrics["calls"] > 0:
                layer_summary[layer] = {
                    "calls": metrics["calls"],
                    "avg_time": metrics["total_time"] / metrics["calls"],
                    "total_time": metrics["total_time"]
                }
        
        return {
            "total_tasks_completed": total_tasks,
            "average_execution_time": avg_execution_time,
            "total_execution_time": self.performance_metrics["total_execution_time"],
            "layer_performance": layer_summary
        }
    
    # ==================== å…¼å®¹æ€§æ¥å£ ====================
    # ä»¥ä¸‹æ–¹æ³•æä¾›ä¸ç°æœ‰AgentOrchestratorçš„å…¼å®¹æ€§
    
    async def initialize_agents(self) -> None:
        """åˆå§‹åŒ–æ™ºèƒ½ä½“ - å…¼å®¹æ€§æ–¹æ³•"""
        logger.info("Haystackç¼–æ’å™¨ï¼šæ™ºèƒ½ä½“åˆå§‹åŒ–ï¼ˆå…¼å®¹æ€§æ¨¡å¼ï¼‰")
        # Haystackç¼–æ’å™¨ä½¿ç”¨å†…ç½®çš„å±‚çº§ç»„ä»¶ï¼Œä¸éœ€è¦å•ç‹¬çš„æ™ºèƒ½ä½“
        # ä½†ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿæ™ºèƒ½ä½“çš„å­˜åœ¨
        self.agents = {
            "haystack_orchestrator": self,
            "txtai_retriever": self.txtai_retriever,
            "r2r_enhancer": self.r2r_enhancer,
            "self_rag_validator": self.self_rag_validator
        }
        logger.info(f"Haystackç¼–æ’å™¨ï¼šå·²åˆå§‹åŒ– {len(self.agents)} ä¸ªç»„ä»¶")
    
    async def extract_code_units(self, source_files: List[SourceFile]) -> List[CodeUnit]:
        """æå–ä»£ç å•å…ƒ - å…¼å®¹æ€§æ–¹æ³•"""
        logger.info(f"Haystackç¼–æ’å™¨ï¼šæå–ä»£ç å•å…ƒï¼Œæ–‡ä»¶æ•°: {len(source_files)}")
        self.code_units = await self._extract_code_units(source_files)
        return self.code_units
    
    async def run_security_analysis(self, source_files: List[SourceFile], 
                                   skip_cross_file: bool = False, 
                                   enhanced_analysis: bool = False) -> List[VulnerabilityResult]:
        """è¿è¡Œå®‰å…¨åˆ†æ - å…¼å®¹æ€§æ–¹æ³•ï¼Œä½¿ç”¨å±‚çº§RAGæ¶æ„"""
        logger.info(f"Haystackç¼–æ’å™¨ï¼šå¼€å§‹å±‚çº§RAGå®‰å…¨åˆ†æï¼Œæ–‡ä»¶æ•°: {len(source_files)}")
        
        try:
            # ä½¿ç”¨å±‚çº§RAGæ¶æ„è¿›è¡Œå®Œæ•´å®¡è®¡
            audit_result = await self.orchestrate_audit(source_files)
            
            logger.info(f"Haystackç¼–æ’å™¨ï¼šå±‚çº§RAGåˆ†æå®Œæˆï¼Œå‘ç°æ¼æ´: {len(audit_result.vulnerabilities)}")
            return audit_result.vulnerabilities
            
        except Exception as e:
            logger.error(f"Haystackç¼–æ’å™¨ï¼šå®‰å…¨åˆ†æå¤±è´¥: {e}")
            return []
    
    async def run_code_structure_analysis(self, code_units: List[CodeUnit]) -> Dict[str, Any]:
        """è¿è¡Œä»£ç ç»“æ„åˆ†æ - å…¼å®¹æ€§æ–¹æ³•"""
        logger.info(f"Haystackç¼–æ’å™¨ï¼šä»£ç ç»“æ„åˆ†æï¼Œä»£ç å•å…ƒæ•°: {len(code_units)}")
        
        # åœ¨Haystackæ¶æ„ä¸­ï¼Œç»“æ„åˆ†ææ˜¯ä»»åŠ¡åˆ†è§£çš„ä¸€éƒ¨åˆ†
        structure_info = {
            "total_units": len(code_units),
            "unit_types": {},
            "file_distribution": {},
            "complexity_metrics": {}
        }
        
        # ç»Ÿè®¡ä»£ç å•å…ƒç±»å‹
        for unit in code_units:
            unit_type = getattr(unit, 'type', 'unknown')
            structure_info["unit_types"][unit_type] = structure_info["unit_types"].get(unit_type, 0) + 1
            
            file_path = str(unit.source_file.path)
            structure_info["file_distribution"][file_path] = structure_info["file_distribution"].get(file_path, 0) + 1
        
        logger.info(f"Haystackç¼–æ’å™¨ï¼šç»“æ„åˆ†æå®Œæˆï¼Œå•å…ƒç±»å‹: {len(structure_info['unit_types'])}")
        return structure_info
    
    async def generate_remediations(self, vulnerabilities: List[VulnerabilityResult]) -> Dict[str, Any]:
        """ç”Ÿæˆä¿®å¤å»ºè®® - å…¼å®¹æ€§æ–¹æ³•"""
        logger.info(f"Haystackç¼–æ’å™¨ï¼šç”Ÿæˆä¿®å¤å»ºè®®ï¼Œæ¼æ´æ•°: {len(vulnerabilities)}")
        
        if not vulnerabilities:
            return {
                "summary": "æœªå‘ç°éœ€è¦ä¿®å¤çš„æ¼æ´",
                "remediation_count": 0,
                "remediations": []
            }
        
        # åœ¨å±‚çº§RAGæ¶æ„ä¸­ï¼Œä¿®å¤å»ºè®®å¯ä»¥é€šè¿‡txtaiå±‚è·å–
        remediations = []
        
        for vuln in vulnerabilities:
            try:
                # ä½¿ç”¨txtaiæ£€ç´¢ä¿®å¤å»ºè®®
                remediation_info = await self.txtai_retriever.get_remediation_suggestions(
                    vuln.vulnerability_type, vuln.description
                )
                
                remediation = {
                    "vulnerability_id": vuln.id,
                    "vulnerability_type": vuln.vulnerability_type,
                    "suggestions": remediation_info.get("suggestions", []),
                    "best_practices": remediation_info.get("best_practices", []),
                    "code_examples": remediation_info.get("code_examples", [])
                }
                remediations.append(remediation)
                
            except Exception as e:
                logger.warning(f"ç”Ÿæˆä¿®å¤å»ºè®®å¤±è´¥: {vuln.id}, {e}")
                # æä¾›åŸºæœ¬çš„ä¿®å¤å»ºè®®
                remediation = {
                    "vulnerability_id": vuln.id,
                    "vulnerability_type": vuln.vulnerability_type,
                    "suggestions": [f"è¯·ä¿®å¤ {vuln.vulnerability_type} æ¼æ´"],
                    "best_practices": ["éµå¾ªå®‰å…¨ç¼–ç è§„èŒƒ"],
                    "code_examples": []
                }
                remediations.append(remediation)
        
        return {
            "summary": f"ä¸º {len(vulnerabilities)} ä¸ªæ¼æ´ç”Ÿæˆäº†ä¿®å¤å»ºè®®",
            "remediation_count": len(remediations),
            "remediations": remediations
        }
    
    async def run_analysis(self, source_files: List[SourceFile]) -> List[VulnerabilityResult]:
        """è¿è¡Œåˆ†æ - å…¼å®¹æ€§æ–¹æ³•ï¼Œç›´æ¥è°ƒç”¨å±‚çº§RAGæ¶æ„"""
        logger.info(f"Haystackç¼–æ’å™¨ï¼šè¿è¡Œå®Œæ•´åˆ†æï¼Œæ–‡ä»¶æ•°: {len(source_files)}")
        return await self.run_security_analysis(source_files)
    
    async def generate_summary(self, vulnerabilities: List[VulnerabilityResult], 
                             assessment: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆæ‘˜è¦ - å…¼å®¹æ€§æ–¹æ³•"""
        if not vulnerabilities:
            return "æœªå‘ç°å®‰å…¨æ¼æ´ã€‚"
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
        severity_counts = {}
        for vuln in vulnerabilities:
            severity = getattr(vuln, 'severity', 'unknown')
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        # æŒ‰ç±»å‹åˆ†ç±»
        type_counts = {}
        for vuln in vulnerabilities:
            vuln_type = vuln.vulnerability_type
            type_counts[vuln_type] = type_counts.get(vuln_type, 0) + 1
        
        # ç”Ÿæˆæ‘˜è¦
        summary_parts = [
            f"ğŸ” Haystackå±‚çº§RAGå®‰å…¨åˆ†ææ‘˜è¦",
            f"ğŸ“Š å‘ç°æ¼æ´æ€»æ•°: {len(vulnerabilities)}",
            "",
            "ğŸ“ˆ ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:"
        ]
        
        for severity, count in sorted(severity_counts.items()):
            summary_parts.append(f"  - {severity}: {count}")
        
        summary_parts.extend([
            "",
            "ğŸ·ï¸ æ¼æ´ç±»å‹åˆ†å¸ƒ:"
        ])
        
        for vuln_type, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):
            summary_parts.append(f"  - {vuln_type}: {count}")
        
        # æ·»åŠ æ€§èƒ½ä¿¡æ¯
        perf_summary = self.get_performance_summary()
        if "total_tasks_completed" in perf_summary:
            summary_parts.extend([
                "",
                "âš¡ æ€§èƒ½æŒ‡æ ‡:",
                f"  - å®Œæˆä»»åŠ¡æ•°: {perf_summary['total_tasks_completed']}",
                f"  - å¹³å‡æ‰§è¡Œæ—¶é—´: {perf_summary.get('average_execution_time', 0):.2f}ç§’"
            ])
        
        return "\n".join(summary_parts)
    
    async def generate_audit_report(self, audit_result: AuditResult) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„å®¡è®¡æŠ¥å‘Š"""
        try:
            # ä½¿ç”¨ç»“æœæ•´åˆå™¨ç”ŸæˆæŠ¥å‘Š
            integration_result_mock = type('IntegrationResult', (), {
                'integrated_vulnerabilities': audit_result.vulnerabilities,
                'duplicate_count': audit_result.execution_summary.get('duplicate_count', 0),
                'conflict_count': audit_result.execution_summary.get('conflict_count', 0),
                'clusters': [],
                'integration_metadata': audit_result.execution_summary.get('integration_metadata', {}),
                'quality_metrics': audit_result.execution_summary.get('quality_metrics', {}),
                'processing_time': audit_result.processing_time
            })()
            
            report = await self.result_integrator.generate_audit_report(
                integration_result_mock, audit_result.task_results
            )
            
            # æ ¼å¼åŒ–æŠ¥å‘Š
            report_text = f"""
{report.title}
{'=' * len(report.title)}

ç”Ÿæˆæ—¶é—´: {report.generated_at}
æŠ¥å‘ŠID: {report.report_id}
å¤„ç†æ—¶é—´: {report.processing_time:.2f}ç§’

{report.summary}

"""
            
            for section in report.sections:
                report_text += f"""
{section.title}
{'-' * len(section.title)}
{section.content}

"""
            
            if report.recommendations:
                report_text += """
å»ºè®®
----
"""
                for i, rec in enumerate(report.recommendations, 1):
                    report_text += f"{i}. {rec}\n"
            
            return report_text
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå®¡è®¡æŠ¥å‘Šå¤±è´¥: {e}")
            return self.generate_summary(audit_result.vulnerabilities, audit_result.execution_summary)