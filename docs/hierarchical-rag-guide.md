# å±‚çº§RAGæ¶æ„æŒ‡å—

## æ¦‚è¿°

AuditLuma 2.0å¼•å…¥äº†åˆ›æ–°çš„**å±‚çº§RAGæ¶æ„**ï¼Œè¿™æ˜¯ä¸€ä¸ªå››å±‚æ™ºèƒ½æ¶æ„ç³»ç»Ÿï¼Œæ˜¾è‘—æå‡äº†ä»£ç å®‰å…¨åˆ†æçš„ç²¾åº¦å’Œæ•ˆç‡ã€‚æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»å±‚çº§RAGæ¶æ„çš„è®¾è®¡ç†å¿µã€ç»„ä»¶åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•ã€‚

## ğŸ—ï¸ æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å±‚çº§RAGæ¶æ„                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç¬¬ä¸€å±‚ï¼šHaystackç¼–æ’å±‚                                        â”‚
â”‚ â”œâ”€ Haystack-AIç¼–æ’å™¨ï¼ˆæ¨èï¼‰- æ™ºèƒ½ä»»åŠ¡åˆ†è§£å’Œç»“æœæ•´åˆ           â”‚
â”‚ â””â”€ ä¼ ç»Ÿç¼–æ’å™¨ - è§„åˆ™é©±åŠ¨çš„ç¨³å®šæ–¹æ¡ˆ                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç¬¬äºŒå±‚ï¼štxtaiçŸ¥è¯†æ£€ç´¢å±‚                                       â”‚
â”‚ â”œâ”€ è¯­ä¹‰æ£€ç´¢å’Œç›¸ä¼¼æ€§åŒ¹é…                                       â”‚
â”‚ â””â”€ ä¸Šä¸‹æ–‡ç†è§£å’ŒçŸ¥è¯†å›¾è°±æ„å»º                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç¬¬ä¸‰å±‚ï¼šR2Rä¸Šä¸‹æ–‡å¢å¼ºå±‚                                       â”‚
â”‚ â”œâ”€ åŠ¨æ€ä¸Šä¸‹æ–‡æ‰©å±•                                            â”‚
â”‚ â””â”€ å…³è”åˆ†æå’Œä¾èµ–è¿½è¸ª                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ç¬¬å››å±‚ï¼šSelf-RAGéªŒè¯å±‚                                        â”‚
â”‚ â”œâ”€ å¤šæ¨¡å‹äº¤å‰éªŒè¯                                            â”‚
â”‚ â””â”€ å‡é˜³æ€§è¿‡æ»¤å’Œç½®ä¿¡åº¦è¯„ä¼°                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ ç¬¬ä¸€å±‚ï¼šHaystackç¼–æ’å±‚

### Haystack-AIç¼–æ’å™¨ï¼ˆæ¨èï¼‰

Haystack-AIç¼–æ’å™¨æ˜¯åŸºäºäººå·¥æ™ºèƒ½çš„æ™ºèƒ½ä»»åŠ¡ç¼–æ’ç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š

- **æ™ºèƒ½ä»»åŠ¡åˆ†è§£**ï¼šè‡ªåŠ¨å°†å¤æ‚çš„ä»£ç åˆ†æä»»åŠ¡åˆ†è§£ä¸ºå¯å¹¶è¡Œæ‰§è¡Œçš„å­ä»»åŠ¡
- **åŠ¨æ€èµ„æºåˆ†é…**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦å’Œç³»ç»Ÿè´Ÿè½½æ™ºèƒ½åˆ†é…è®¡ç®—èµ„æº
- **ç»“æœæ™ºèƒ½æ•´åˆ**ï¼šä½¿ç”¨AIæŠ€æœ¯æ•´åˆå¤šä¸ªåˆ†æç»“æœï¼Œæä¾›æ›´å‡†ç¡®çš„ç»¼åˆè¯„ä¼°
- **è‡ªé€‚åº”ä¼˜åŒ–**ï¼šæ ¹æ®å†å²åˆ†æç»“æœæŒç»­ä¼˜åŒ–ä»»åŠ¡åˆ†è§£ç­–ç•¥

#### é…ç½®ç¤ºä¾‹

```yaml
hierarchical_rag_models:
  haystack:
    orchestrator_type: "ai"  # ä½¿ç”¨Haystack-AIç¼–æ’å™¨
    default_model: "gpt-4@openai"
    task_models:
      security_scan: "gpt-4@openai"
      syntax_check: "deepseek-chat@deepseek"
      logic_analysis: "qwen-turbo@qwen"
      dependency_analysis: "gpt-3.5-turbo@openai"
```

#### ä½¿ç”¨æ–¹æ³•

```bash
# ä½¿ç”¨Haystack-AIç¼–æ’å™¨ï¼ˆé»˜è®¤ï¼‰
python main.py --architecture hierarchical --haystack-orchestrator ai

# æŸ¥çœ‹ç¼–æ’å™¨çŠ¶æ€
python main.py --show-architecture-info
```

### ä¼ ç»Ÿç¼–æ’å™¨

ä¼ ç»Ÿç¼–æ’å™¨æä¾›è§„åˆ™é©±åŠ¨çš„ç¨³å®šç¼–æ’æ–¹æ¡ˆï¼Œé€‚ç”¨äºï¼š

- **ç¨³å®šæ€§è¦æ±‚é«˜**çš„ç”Ÿäº§ç¯å¢ƒ
- **ç½‘ç»œå—é™**çš„ç¯å¢ƒï¼ˆå‡å°‘AI APIè°ƒç”¨ï¼‰
- **æˆæœ¬æ•æ„Ÿ**çš„åœºæ™¯

#### é…ç½®ç¤ºä¾‹

```yaml
hierarchical_rag_models:
  haystack:
    orchestrator_type: "traditional"  # ä½¿ç”¨ä¼ ç»Ÿç¼–æ’å™¨
```

#### ä½¿ç”¨æ–¹æ³•

```bash
# ä½¿ç”¨ä¼ ç»Ÿç¼–æ’å™¨
python main.py --architecture hierarchical --haystack-orchestrator traditional
```

### è‡ªåŠ¨å›é€€æœºåˆ¶

ç³»ç»Ÿæä¾›æ™ºèƒ½å›é€€æœºåˆ¶ï¼Œå½“Haystack-AIç¼–æ’å™¨ä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°ä¼ ç»Ÿç¼–æ’å™¨ï¼š

```python
# è‡ªåŠ¨å›é€€é€»è¾‘ç¤ºä¾‹
try:
    # å°è¯•ä½¿ç”¨Haystack-AIç¼–æ’å™¨
    orchestrator = HaystackAIOrchestrator(config)
    logger.info("âœ… ä½¿ç”¨Haystack-AIç¼–æ’å™¨")
except Exception as e:
    # å›é€€åˆ°ä¼ ç»Ÿç¼–æ’å™¨
    orchestrator = HaystackOrchestrator(config)
    logger.warning(f"âš ï¸ Haystack-AIç¼–æ’å™¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°ä¼ ç»Ÿç¼–æ’å™¨: {e}")
```

## ğŸ” ç¬¬äºŒå±‚ï¼štxtaiçŸ¥è¯†æ£€ç´¢å±‚

txtaiçŸ¥è¯†æ£€ç´¢å±‚æä¾›å¼ºå¤§çš„è¯­ä¹‰æ£€ç´¢å’ŒçŸ¥è¯†ç†è§£èƒ½åŠ›ï¼š

### æ ¸å¿ƒåŠŸèƒ½

1. **è¯­ä¹‰æ£€ç´¢**
   - åŸºäºå‘é‡ç›¸ä¼¼æ€§çš„ä»£ç ç‰‡æ®µæ£€ç´¢
   - æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢ä»£ç åŠŸèƒ½
   - æ™ºèƒ½ä»£ç æ¨¡å¼åŒ¹é…

2. **çŸ¥è¯†å›¾è°±æ„å»º**
   - è‡ªåŠ¨æ„å»ºä»£ç çŸ¥è¯†å›¾è°±
   - å‡½æ•°è°ƒç”¨å…³ç³»æ˜ å°„
   - æ•°æ®æµä¾èµ–åˆ†æ

3. **ä¸Šä¸‹æ–‡ç†è§£**
   - æ·±åº¦ç†è§£ä»£ç è¯­ä¹‰
   - è·¨æ–‡ä»¶ä¸Šä¸‹æ–‡å…³è”
   - ä¸šåŠ¡é€»è¾‘æ¨ç†

### é…ç½®ç¤ºä¾‹

```yaml
hierarchical_rag_models:
  txtai:
    retrieval_model: "gpt-3.5-turbo@openai"
    embedding_model: "text-embedding-ada-002@openai"
    index_config:
      dimensions: 1536
      metric: "cosine"
      quantize: true
```

### ä½¿ç”¨æ–¹æ³•

```bash
# å¯ç”¨txtaiçŸ¥è¯†æ£€ç´¢å±‚
python main.py --architecture hierarchical --enable-txtai
```

## ğŸ¯ ç¬¬ä¸‰å±‚ï¼šR2Rä¸Šä¸‹æ–‡å¢å¼ºå±‚

R2Rï¼ˆRetrieval-to-Retrievalï¼‰ä¸Šä¸‹æ–‡å¢å¼ºå±‚æä¾›åŠ¨æ€ä¸Šä¸‹æ–‡æ‰©å±•å’Œå…³è”åˆ†æï¼š

### æ ¸å¿ƒåŠŸèƒ½

1. **åŠ¨æ€ä¸Šä¸‹æ–‡æ‰©å±•**
   - æ ¹æ®åˆ†æéœ€æ±‚åŠ¨æ€æ‰©å±•ä¸Šä¸‹æ–‡èŒƒå›´
   - æ™ºèƒ½è¯†åˆ«ç›¸å…³ä»£ç ç‰‡æ®µ
   - è‡ªé€‚åº”ä¸Šä¸‹æ–‡çª—å£è°ƒæ•´

2. **å…³è”åˆ†æ**
   - è·¨æ–‡ä»¶ä¾èµ–å…³ç³»åˆ†æ
   - æ•°æ®æµè¿½è¸ªå’Œæ±¡ç‚¹åˆ†æ
   - ä¸šåŠ¡é€»è¾‘å…³è”æ¨ç†

3. **ä¾èµ–è¿½è¸ª**
   - å‡½æ•°è°ƒç”¨é“¾è¿½è¸ª
   - å˜é‡ç”Ÿå‘½å‘¨æœŸåˆ†æ
   - æ¨¡å—é—´ä¾èµ–æ˜ å°„

### é…ç½®ç¤ºä¾‹

```yaml
hierarchical_rag_models:
  r2r:
    context_model: "gpt-3.5-turbo@openai"
    enhancement_model: "gpt-4@openai"
    context_config:
      max_context_length: 8000
      expansion_strategy: "adaptive"
      relevance_threshold: 0.7
```

### ä½¿ç”¨æ–¹æ³•

```bash
# å¯ç”¨R2Rä¸Šä¸‹æ–‡å¢å¼ºå±‚
python main.py --architecture hierarchical --enable-r2r
```

## ğŸ›¡ï¸ ç¬¬å››å±‚ï¼šSelf-RAGéªŒè¯å±‚

Self-RAGéªŒè¯å±‚æ˜¯å±‚çº§æ¶æ„çš„æœ€åä¸€å±‚ï¼Œæä¾›å¤šæ¨¡å‹äº¤å‰éªŒè¯å’Œå‡é˜³æ€§è¿‡æ»¤ï¼š

### æ ¸å¿ƒåŠŸèƒ½

1. **å¤šæ¨¡å‹äº¤å‰éªŒè¯**
   - ä½¿ç”¨å¤šä¸ªä¸åŒçš„AIæ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯
   - æé«˜æ¼æ´æ£€æµ‹çš„å‡†ç¡®æ€§
   - å‡å°‘å•ä¸€æ¨¡å‹çš„åè§

2. **å‡é˜³æ€§è¿‡æ»¤**
   - æ™ºèƒ½è¯†åˆ«å’Œè¿‡æ»¤å‡é˜³æ€§ç»“æœ
   - åŸºäºç½®ä¿¡åº¦çš„ç»“æœç­›é€‰
   - å†å²æ•°æ®å­¦ä¹ ä¼˜åŒ–

3. **ç½®ä¿¡åº¦è¯„ä¼°**
   - ä¸ºæ¯ä¸ªæ£€æµ‹ç»“æœæä¾›ç½®ä¿¡åº¦è¯„åˆ†
   - æ”¯æŒåŸºäºç½®ä¿¡åº¦çš„ç»“æœæ’åº
   - æä¾›è¯¦ç»†çš„éªŒè¯æŠ¥å‘Š

### é…ç½®ç¤ºä¾‹

```yaml
hierarchical_rag_models:
  self_rag_validation:
    validation_model: "gpt-4@openai"
    cross_validation_models:
      - "gpt-4@openai"
      - "deepseek-chat@deepseek"
      - "claude-3@anthropic"
    validation_config:
      min_confidence: 0.7
      consensus_threshold: 0.6
      max_iterations: 3
```

### ä½¿ç”¨æ–¹æ³•

```bash
# å¯ç”¨Self-RAGéªŒè¯å±‚
python main.py --architecture hierarchical --enable-self-rag-validation
```

## ğŸ”§ å®Œæ•´é…ç½®ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„å±‚çº§RAGæ¶æ„é…ç½®ç¤ºä¾‹ï¼š

```yaml
# å±‚çº§RAGæ¶æ„æ¨¡å‹é…ç½®
hierarchical_rag_models:
  # å¯ç”¨å±‚çº§RAGæ¶æ„
  enabled: true
  
  # Haystackç¼–æ’å±‚é…ç½®
  haystack:
    orchestrator_type: "ai"  # ä½¿ç”¨Haystack-AIç¼–æ’å™¨
    default_model: "gpt-4@openai"
    task_models:
      security_scan: "gpt-4@openai"
      syntax_check: "deepseek-chat@deepseek"
      logic_analysis: "qwen-turbo@qwen"
      dependency_analysis: "gpt-3.5-turbo@openai"
    orchestrator_config:
      max_parallel_tasks: 10
      timeout: 300
      retry_attempts: 3
  
  # txtaiçŸ¥è¯†æ£€ç´¢å±‚é…ç½®
  txtai:
    retrieval_model: "gpt-3.5-turbo@openai"
    embedding_model: "text-embedding-ada-002@openai"
    index_config:
      dimensions: 1536
      metric: "cosine"
      quantize: true
      batch_size: 100
  
  # R2Rä¸Šä¸‹æ–‡å¢å¼ºå±‚é…ç½®
  r2r:
    context_model: "gpt-3.5-turbo@openai"
    enhancement_model: "gpt-4@openai"
    context_config:
      max_context_length: 8000
      expansion_strategy: "adaptive"
      relevance_threshold: 0.7
      max_expansions: 5
  
  # Self-RAGéªŒè¯å±‚é…ç½®
  self_rag_validation:
    validation_model: "gpt-4@openai"
    cross_validation_models:
      - "gpt-4@openai"
      - "deepseek-chat@deepseek"
      - "claude-3@anthropic"
    validation_config:
      min_confidence: 0.7
      consensus_threshold: 0.6
      max_iterations: 3
      enable_false_positive_filter: true

# ç¼“å­˜é…ç½®
hierarchical_cache:
  enabled: true
  cache_layers:
    - "haystack"
    - "txtai"
    - "r2r"
    - "self_rag"
  ttl: 3600  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
  max_size: 1000  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°

# ç›‘æ§é…ç½®
hierarchical_monitoring:
  enabled: true
  metrics:
    - "performance"
    - "accuracy"
    - "resource_usage"
  export_format: "prometheus"
```

## ğŸš€ ä½¿ç”¨æœ€ä½³å®è·µ

### 1. æ¶æ„é€‰æ‹©å»ºè®®

- **å°é¡¹ç›®ï¼ˆ<100æ–‡ä»¶ï¼‰**ï¼šä½¿ç”¨ä¼ ç»Ÿæ¶æ„æˆ–è‡ªåŠ¨æ¨¡å¼
- **ä¸­å‹é¡¹ç›®ï¼ˆ100-1000æ–‡ä»¶ï¼‰**ï¼šæ¨èä½¿ç”¨å±‚çº§æ¶æ„
- **å¤§å‹é¡¹ç›®ï¼ˆ>1000æ–‡ä»¶ï¼‰**ï¼šå¼ºçƒˆæ¨èä½¿ç”¨å±‚çº§æ¶æ„

### 2. ç¼–æ’å™¨é€‰æ‹©å»ºè®®

- **ç”Ÿäº§ç¯å¢ƒ**ï¼šæ¨èä½¿ç”¨Haystack-AIç¼–æ’å™¨ï¼Œé…ç½®è‡ªåŠ¨å›é€€
- **å¼€å‘ç¯å¢ƒ**ï¼šå¯ä»¥ä½¿ç”¨ä»»ä¸€ç¼–æ’å™¨è¿›è¡Œæµ‹è¯•
- **èµ„æºå—é™ç¯å¢ƒ**ï¼šä½¿ç”¨ä¼ ç»Ÿç¼–æ’å™¨

### 3. æ¨¡å‹é…ç½®å»ºè®®

- **å®‰å…¨æ‰«æ**ï¼šä½¿ç”¨æœ€å¼ºçš„æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰
- **è¯­æ³•æ£€æŸ¥**ï¼šå¯ä»¥ä½¿ç”¨è¾ƒè½»é‡çš„æ¨¡å‹
- **äº¤å‰éªŒè¯**ï¼šä½¿ç”¨å¤šæ ·åŒ–çš„æ¨¡å‹ç»„åˆ

### 4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

- å¯ç”¨å±‚çº§ç¼“å­˜ç³»ç»Ÿ
- åˆç†é…ç½®å¹¶è¡Œä»»åŠ¡æ•°é‡
- æ ¹æ®é¡¹ç›®è§„æ¨¡è°ƒæ•´ä¸Šä¸‹æ–‡é•¿åº¦

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### å¯ç”¨è¯¦ç»†æ—¥å¿—

```bash
python main.py --architecture hierarchical --verbose
```

### æŸ¥çœ‹æ¶æ„ä¿¡æ¯

```bash
python main.py --show-architecture-info
```

### æ€§èƒ½å¯¹æ¯”æ¨¡å¼

```bash
python main.py --architecture hierarchical --enable-performance-comparison
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Haystack-AIç¼–æ’å™¨åˆå§‹åŒ–å¤±è´¥**
   - æ£€æŸ¥APIå¯†é’¥é…ç½®
   - éªŒè¯ç½‘ç»œè¿æ¥
   - æŸ¥çœ‹è‡ªåŠ¨å›é€€æ—¥å¿—

2. **txtaiæ£€ç´¢æ€§èƒ½å·®**
   - æ£€æŸ¥åµŒå…¥æ¨¡å‹é…ç½®
   - è°ƒæ•´æ‰¹å¤„ç†å¤§å°
   - è€ƒè™‘ä½¿ç”¨é‡åŒ–ç´¢å¼•

3. **Self-RAGéªŒè¯è¶…æ—¶**
   - å¢åŠ è¶…æ—¶æ—¶é—´é…ç½®
   - å‡å°‘äº¤å‰éªŒè¯æ¨¡å‹æ•°é‡
   - è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼

### è°ƒè¯•å‘½ä»¤

```bash
# è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸æ‰§è¡Œå®é™…åˆ†æï¼‰
python main.py --architecture hierarchical --dry-run

# ç¦ç”¨ç‰¹å®šå±‚è¿›è¡Œè°ƒè¯•
python main.py --architecture hierarchical --disable-caching --disable-monitoring
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

å±‚çº§RAGæ¶æ„ç›¸æ¯”ä¼ ç»Ÿæ¶æ„çš„æ€§èƒ½æå‡ï¼š

- **å‡†ç¡®ç‡æå‡**ï¼š30-50%
- **å‡é˜³æ€§å‡å°‘**ï¼š40-60%
- **åˆ†æé€Ÿåº¦**ï¼šæå‡20-30%ï¼ˆå¯ç”¨ç¼“å­˜ï¼‰
- **èµ„æºåˆ©ç”¨ç‡**ï¼šæå‡25-40%

## ğŸ”„ è¿ç§»æŒ‡å—

ä»ä¼ ç»Ÿæ¶æ„è¿ç§»åˆ°å±‚çº§RAGæ¶æ„ï¼š

```bash
# 1. å¤‡ä»½ç°æœ‰é…ç½®
cp config/config.yaml config/config.yaml.backup

# 2. è¿è¡Œé…ç½®è¿ç§»
python main.py --config-migrate

# 3. éªŒè¯æ–°é…ç½®
python main.py --show-architecture-info

# 4. æµ‹è¯•è¿è¡Œ
python main.py --architecture hierarchical --dry-run
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [é…ç½®å‚è€ƒ](./configuration-reference.md) - å®Œæ•´çš„é…ç½®é€‰é¡¹è¯´æ˜
- [æ•…éšœæ’é™¤æŒ‡å—](./troubleshooting.md) - å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- [æœ€ä½³å®è·µ](./best-practices.md) - ä½¿ç”¨å»ºè®®å’Œä¼˜åŒ–æŠ€å·§
- [æ¶æ„è®¾è®¡](./architecture-design.md) - ç³»ç»Ÿæ¶æ„å’Œè®¾è®¡ç†å¿µ

---

*æœ¬æŒ‡å—æŒç»­æ›´æ–°ä¸­ï¼Œå¦‚æœ‰é—®é¢˜è¯·å‚è€ƒæ•…éšœæ’é™¤æŒ‡å—æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚*
### Python APIä½¿ç”¨

```python
from auditluma.models.hierarchical_rag import HierarchicalRAGModel
from auditluma.config import Config

# åˆå§‹åŒ–å±‚çº§RAGæ¨¡å‹
model = HierarchicalRAGModel(
    orchestrator_type="ai",
    enable_txtai=True,
    enable_r2r=True,
    enable_self_rag_validation=True
)

# åˆ†æä»£ç 
results = await model.analyze_code(
    code_path="./your-project",
    analysis_type="security_scan"
)

# è·å–åˆ†æç»“æœ
vulnerabilities = results.get_vulnerabilities()
confidence_scores = results.get_confidence_scores()
```

## æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ä¼˜åŒ–

```yaml
# å¯ç”¨æ™ºèƒ½ç¼“å­˜
hierarchical_cache:
  enabled: true
  
  # ç¼“å­˜ç­–ç•¥
  strategy: "lru"  # lru, lfu, ttl
  
  # åˆ†å±‚ç¼“å­˜é…ç½®
  layers:
    haystack:
      enabled: true
      ttl: 3600
      max_entries: 1000
    txtai:
      enabled: true
      ttl: 7200
      max_entries: 5000
    r2r:
      enabled: true
      ttl: 1800
      max_entries: 2000
    self_rag:
      enabled: true
      ttl: 900
      max_entries: 500
```

### å¹¶å‘ä¼˜åŒ–

```yaml
# å¹¶å‘é…ç½®
concurrency:
  # æ¯å±‚çš„å¹¶å‘é…ç½®
  haystack:
    max_workers: 4
    batch_size: 10
  txtai:
    max_workers: 8
    batch_size: 20
  r2r:
    max_workers: 6
    batch_size: 15
  self_rag:
    max_workers: 2
    batch_size: 5
```

### æ¨¡å‹ä¼˜åŒ–

```yaml
# æ¨¡å‹é€‰æ‹©ä¼˜åŒ–
hierarchical_rag_models:
  haystack:
    # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©æ¨¡å‹
    task_models:
      simple_syntax: "gpt-3.5-turbo@openai"  # ç®€å•ä»»åŠ¡ç”¨è½»é‡æ¨¡å‹
      complex_security: "gpt-4@openai"       # å¤æ‚ä»»åŠ¡ç”¨å¼ºåŠ›æ¨¡å‹
      
  # æ¨¡å‹è´Ÿè½½å‡è¡¡
  load_balancing:
    enabled: true
    strategy: "round_robin"  # round_robin, least_loaded, random
```

## ç›‘æ§å’Œè°ƒè¯•

### æ€§èƒ½ç›‘æ§

```bash
# å¯ç”¨è¯¦ç»†ç›‘æ§
python main.py --architecture hierarchical \
  --verbose \
  --enable-monitoring \
  -d ./your-project
```

ç›‘æ§æŒ‡æ ‡åŒ…æ‹¬ï¼š
- **å“åº”æ—¶é—´** - æ¯å±‚çš„å¤„ç†æ—¶é—´
- **å†…å­˜ä½¿ç”¨** - å„ç»„ä»¶çš„å†…å­˜å ç”¨
- **ç¼“å­˜å‘½ä¸­ç‡** - ç¼“å­˜æ•ˆç‡ç»Ÿè®¡
- **æ¨¡å‹è°ƒç”¨æ¬¡æ•°** - APIè°ƒç”¨ç»Ÿè®¡
- **é”™è¯¯ç‡** - å„å±‚çš„é”™è¯¯ç»Ÿè®¡

### è°ƒè¯•æ¨¡å¼

```bash
# è°ƒè¯•æ¨¡å¼
python main.py --architecture hierarchical \
  --verbose \
  --disable-caching \
  --dry-run \
  -d ./your-project
```

è°ƒè¯•åŠŸèƒ½ï¼š
- **è¯¦ç»†æ—¥å¿—** - æ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯
- **ç¦ç”¨ç¼“å­˜** - ç¡®ä¿è·å–æœ€æ–°ç»“æœ
- **è¯•è¿è¡Œæ¨¡å¼** - ä¸æ‰§è¡Œå®é™…åˆ†æï¼Œä»…éªŒè¯é…ç½®
- **æ€§èƒ½åˆ†æ** - è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡

### æ—¥å¿—é…ç½®

```yaml
# æ—¥å¿—é…ç½®
logging:
  level: "DEBUG"  # DEBUG, INFO, WARNING, ERROR
  
  # åˆ†å±‚æ—¥å¿—é…ç½®
  layers:
    haystack: "INFO"
    txtai: "DEBUG"
    r2r: "INFO"
    self_rag: "WARNING"
  
  # è¾“å‡ºé…ç½®
  handlers:
    - type: "console"
      level: "INFO"
    - type: "file"
      level: "DEBUG"
      filename: "./logs/hierarchical_rag.log"
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç¼–æ’å™¨åˆå§‹åŒ–å¤±è´¥**
   ```bash
   # æ£€æŸ¥é…ç½®
   python main.py --show-architecture-info
   
   # å¼ºåˆ¶ä½¿ç”¨ä¼ ç»Ÿç¼–æ’å™¨
   python main.py --haystack-orchestrator traditional
   ```

2. **å†…å­˜ä¸è¶³**
   ```yaml
   # å‡å°‘å¹¶å‘æ•°
   concurrency:
     max_workers: 2
     batch_size: 5
   
   # å¯ç”¨ç¼“å­˜æ¸…ç†
   hierarchical_cache:
     auto_cleanup: true
     max_size: "500MB"
   ```

3. **æ¨¡å‹è°ƒç”¨å¤±è´¥**
   ```yaml
   # é…ç½®å›é€€æ¨¡å‹
   hierarchical_rag_models:
     haystack:
       fallback_models:
         - "gpt-3.5-turbo@openai"
         - "deepseek-chat@deepseek"
   ```

### æ€§èƒ½è°ƒä¼˜å»ºè®®

1. **å°å‹é¡¹ç›®**ï¼ˆ<100æ–‡ä»¶ï¼‰
   - ä½¿ç”¨ä¼ ç»Ÿç¼–æ’å™¨
   - å‡å°‘äº¤å‰éªŒè¯æ¨¡å‹æ•°é‡
   - å¯ç”¨ç§¯æç¼“å­˜

2. **ä¸­å‹é¡¹ç›®**ï¼ˆ100-1000æ–‡ä»¶ï¼‰
   - ä½¿ç”¨Haystack-AIç¼–æ’å™¨
   - å¹³è¡¡ç²¾åº¦å’Œæ€§èƒ½
   - å¯ç”¨åˆ†å±‚ç¼“å­˜

3. **å¤§å‹é¡¹ç›®**ï¼ˆ>1000æ–‡ä»¶ï¼‰
   - ä½¿ç”¨å®Œæ•´å±‚çº§RAGæ¶æ„
   - å¯ç”¨æ‰€æœ‰ä¼˜åŒ–é€‰é¡¹
   - è€ƒè™‘åˆ†å¸ƒå¼éƒ¨ç½²

---

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒï¼š
- [é…ç½®å‚è€ƒ](./configuration-reference.md)
- [æ•…éšœæ’é™¤æŒ‡å—](./troubleshooting.md)
- [æœ€ä½³å®è·µ](./best-practices.md)